{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MIP\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import cupy as cp\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imread, imsave\n",
    "from cupyx.scipy.ndimage import minimum_filter\n",
    "import re\n",
    "\n",
    "\n",
    "def rolling_ball_gpu(image, radius):\n",
    "    \"\"\"\n",
    "    Using CuPy\n",
    "    \"\"\"\n",
    "    kernel_size = int(2 * radius + 1)\n",
    "    # minimam filter\n",
    "    gpu_background = minimum_filter(image, size=kernel_size)\n",
    "    # remove background\n",
    "    gpu_result = image - gpu_background\n",
    "    # clip of negative values\n",
    "    gpu_result = cp.clip(gpu_result, 0, None)\n",
    "    return gpu_result\n",
    "\n",
    "# setting image directory\n",
    "origin_dir = r\"your origin directory\"\n",
    "save_dir = r\"green_mip\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# get list of image dir\n",
    "sample_images = [os.path.join(origin_dir, tif) for tif in os.listdir(origin_dir) if tif.endswith(\".tif\")]\n",
    "\n",
    "for i, sample_image in enumerate(sample_images):\n",
    "    # process each sample image directory\n",
    "    image_file = os.path.basename(sample_image)\n",
    "    sample_name = image_file.split(\".\")[0]\n",
    "    sample_label_name = re.split(r'[-]', sample_name)\n",
    "    sample_name_filter_list = re.split(r'[-_]',sample_name)\n",
    "\n",
    "\n",
    "    if \"nx\" in sample_name_filter_list:\n",
    "\n",
    "        sample_label_name = \"-\".join(sample_name_filter_list[6:9])\n",
    "\n",
    "    elif \"during\" in sample_name_filter_list:\n",
    "        sample_label_name = sample_name_filter_list[3]\n",
    "\n",
    "    save_label_name = \"-\".join(sample_name_filter_list[2].split('_')[0:3])\n",
    "\n",
    "\n",
    "    # Image loading and Z-stack integration\n",
    "    z_stack = imread(sample_image)\n",
    "\n",
    "    # Apply background processing to each slice\n",
    "    radius = 50  # Rolling ball radius\n",
    "    processed_slices = []\n",
    "\n",
    "    for slice_idx, slice_image in enumerate(z_stack):\n",
    "\n",
    "        # Transfer the image to the GPU\n",
    "        gpu_image = cp.asarray(slice_image)\n",
    "\n",
    "        # Gaussian Filter (GPU)\n",
    "        gpu_blurred = cv2.GaussianBlur(cp.asnumpy(gpu_image), (0, 0), sigmaX=2)\n",
    "\n",
    "        # Rolling ball background removal (GPU)\n",
    "        gpu_result = rolling_ball_gpu(cp.asarray(gpu_blurred), radius=300)\n",
    "\n",
    "        # save result as cpu format\n",
    "        result_image = cp.asnumpy(gpu_result)\n",
    "\n",
    "        processed_slices.append(result_image)\n",
    "\n",
    "    # Convert background processed Z-stack to NumPy array\n",
    "    processed_z_stack = np.array(processed_slices)\n",
    "\n",
    "    # MIP\n",
    "    mip_image = np.max(processed_z_stack, axis=0)\n",
    "\n",
    "    # **Check the shape of the mip_image and make it 2D**\n",
    "    if mip_image.ndim == 3:\n",
    "        mip_image = mip_image[:, :, 1]  # Get only the green channel\n",
    "    elif mip_image.ndim != 2:\n",
    "        raise ValueError(f\"Unexpected MIP image shape: {mip_image.shape}\")\n",
    "\n",
    "    # **to RGB image**\n",
    "    mip_green = (mip_image / mip_image.max() * 255).astype(np.uint8)  # Normalized to 0-255\n",
    "    mip_rgb = cv2.merge([np.zeros_like(mip_green), mip_green, np.zeros_like(mip_green)])  # (H, W, 3)\n",
    "\n",
    "    # **save**\n",
    "    output_path = os.path.join(save_dir, f\"{sample_label_name}_mip-green.tif\")\n",
    "    imsave(output_path, mip_rgb)\n",
    "\n",
    "    print(f\"Processed {sample_name} and saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FFT\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "def gaussian_high_pass_filter(image, cutoff=1000):\n",
    "    \"\"\"\n",
    "    Apply Gaussian High-Pass Filter (GHPF) to a 2D image\n",
    "    Args: \n",
    "        image (numpy.ndarray): Grayscale image\n",
    "        cutoff (int): Cutoff frequency (larger value leaves more high frequencies)\n",
    "    Returns:\n",
    "        numpy.ndarray: Image after high frequency emphasis\n",
    "    \"\"\"\n",
    "    # Fourier transform of an image\n",
    "    dft = np.fft.fft2(image)\n",
    "    dft_shift = np.fft.fftshift(dft)  # Centering on frequency components\n",
    "\n",
    "    # Get Image Size\n",
    "    rows, cols = image.shape\n",
    "    crow, ccol = rows // 2, cols // 2  # image center coordinates\n",
    "\n",
    "    # Creating a Gaussian High-Pass Filter\n",
    "    x, y = np.meshgrid(np.linspace(-1, 1, cols), np.linspace(-1, 1, rows))\n",
    "    radius = np.sqrt(x**2 + y**2)\n",
    "    ghpf = 1 - np.exp(- (radius * cutoff) ** 2)  # emphasize high frequencies\n",
    "\n",
    "    # Apply filter\n",
    "    dft_shift_filtered = dft_shift * ghpf\n",
    "\n",
    "    # Return to the image using the inverse Fourier transform\n",
    "    dft_inverse_shift = np.fft.ifftshift(dft_shift_filtered)\n",
    "    image_filtered = np.fft.ifft2(dft_inverse_shift)\n",
    "    image_filtered = np.abs(image_filtered)\n",
    "\n",
    "    # Normalize and scale to 0-255\n",
    "    image_filtered = cv2.normalize(image_filtered, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "\n",
    "    return image_filtered\n",
    "\n",
    "# Specifying the image directory\n",
    "origin_dir = r\"green_mip\"\n",
    "save_dir = r\"fft\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Get list of TIFF images\n",
    "sample_images = [os.path.join(origin_dir, tif) for tif in os.listdir(origin_dir) if tif.endswith(\".tif\")]\n",
    "\n",
    "for i, sample_image in enumerate(sample_images):\n",
    "    # sample image director\n",
    "    image_file = os.path.basename(sample_image)\n",
    "    sample_name = image_file.split(\".\")[0]\n",
    "    sample_label_name = re.split(r'[-]', sample_name)\n",
    "    sample_name_filter_list = re.split(r'[-_]',sample_name)\n",
    "\n",
    "    # Image loading and Z-stack integration\n",
    "    image = imread(sample_image)\n",
    "\n",
    "    g_channnel = image[:,:,1]\n",
    "\n",
    "    fft_image = gaussian_high_pass_filter(g_channnel)\n",
    "\n",
    "    # save\n",
    "    output_path = os.path.join(save_dir, f\"{sample_name}_fft_filter.tif\")\n",
    "    imsave(output_path, fft_image)\n",
    "\n",
    "    print(f\"Processed {sample_name} and saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plese make ROI of cells using \"make_extract_ROI.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract cell\n",
    "\n",
    "import tifffile as tiff\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from skimage.draw import polygon\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.measure import label\n",
    "import re\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def load_shapes_json(json_path):\n",
    "    \"\"\"Load ROI data from JSON\"\"\"\n",
    "    with open(json_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    return data[\"rois\"]\n",
    "\n",
    "\n",
    "def extract_roi_regions(image, roi_shapes):\n",
    "    \"\"\"\n",
    "    Create a new image for each ROI (fill in black outside the ROI)\n",
    "    :param image: 2D image (H, W)\n",
    "    :param roi_shapes: A list of [[(x1, y1), (x2, y2), ...], ...]\n",
    "    :return: Mask image list for each ROI\n",
    "    \"\"\"\n",
    "    masked_images = []  # A list to save masked images\n",
    "    extracted_images = []  # A list to store images for each ROI\n",
    "\n",
    "    for roi in roi_shapes: \n",
    "        masked_image = np.zeros_like(image) \n",
    "        \n",
    "        roi_np = np.array(roi)\n",
    "        rr, cc = polygon(roi_np[:, 0], roi_np[:, 1], shape=image.shape) \n",
    "        \n",
    "        # Apply mask (ROI area to original pixel values)\n",
    "        masked_image[rr, cc] = image[rr, cc]\n",
    "        \n",
    "        # Get the minimum and maximum coordinates of the ROI region\n",
    "        min_r, max_r = np.min(rr), np.max(rr)\n",
    "        min_c, max_c = np.min(cc), np.max(cc)\n",
    "        \n",
    "        # Extract ROI area (not including background)\n",
    "        roi_image = masked_image[min_r:max_r+1, min_c:max_c+1]\n",
    "        extracted_images.append(roi_image) \n",
    "\n",
    "    extracted_images = np.array(extracted_images)\n",
    "    return extracted_images\n",
    "\n",
    "# Process\n",
    "slice_start_index = []\n",
    "\n",
    "# save directory\n",
    "result_savedir = r\"ROI_extracted_regions\"\n",
    "os.makedirs(result_savedir, exist_ok=True)\n",
    "\n",
    "# Image directory\n",
    "image_dir = r\"fft\"\n",
    "image_files = [os.path.join(image_dir, tif) for tif in os.listdir(image_dir) if tif.endswith(\".tif\")]\n",
    "\n",
    "# Get roi directory\n",
    "roi_dirs = {}\n",
    "\n",
    "# Matching images and ROIs for processing\n",
    "for image_path in image_files:\n",
    "    \n",
    "    image_file = os.path.basename(image_path)\n",
    "    sample_name = image_file.split(\"_\")[0]\n",
    "\n",
    "    # load image\n",
    "    image_file = os.path.basename(image_path)\n",
    "    image = tiff.imread(image_path)\n",
    "\n",
    "    if len(image.shape) == 3:\n",
    "        g_channnel = image[:,:,1]\n",
    "    else:\n",
    "        g_channnel  = image\n",
    "\n",
    "    print(f\"Processing: {sample_name}\")\n",
    "\n",
    "    roi_sample_dir = \"ROI_json\" + \"/\" + sample_name\n",
    "    roi_files = [os.path.join(roi_sample_dir, roi) for roi in os.listdir(roi_sample_dir) if roi.endswith(\".json\")]\n",
    "\n",
    "\n",
    "    for i, json_path in enumerate(tqdm(roi_files)):\n",
    "\n",
    "        output_path = os.path.join(result_savedir, f\"{sample_name}-roi-{i}.tif\")\n",
    "        if os.path.exists(output_path):\n",
    "            continue\n",
    "\n",
    "        # Load JSON\n",
    "        rois = load_shapes_json(json_path)\n",
    "        # Apply ROI and acquire images for each ROI\n",
    "        extract_images = extract_roi_regions(g_channnel, rois)\n",
    "\n",
    "        tiff.imwrite(output_path, extract_images)\n",
    "        \n",
    "    \n",
    "\"\"\"\n",
    "# Saving the acquired image\n",
    "import tifffile as tiff\n",
    "import os\n",
    "import napari\n",
    "\n",
    "\n",
    "extracted_image_dir = r\"ROI_extracted_regions\"\n",
    "extracted_images = [os.path.join(extracted_image_dir, roi) for roi in os.listdir(extracted_image_dir) if roi.endswith(\".tif\")]\n",
    "\n",
    "for i, image_path in enumerate(extracted_images):\n",
    "    image = tiff.imread(image_path)\n",
    "    \n",
    "    if i % 10 == 1000:\n",
    "        print(image_path)\n",
    "        vi = napari.Viewer()\n",
    "        vi.add_image(image)\n",
    "        napari.run()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from skimage.io import imread, imsave\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.measure import label, regionprops\n",
    "\n",
    "# save directory\n",
    "result_savedir = r\"Threshold\"\n",
    "os.makedirs(result_savedir, exist_ok=True)\n",
    "\n",
    "# image directory\n",
    "image_dir = r\"ROI_extracted_regions\"\n",
    "image_files = [os.path.join(image_dir, tif) for tif in os.listdir(image_dir) if tif.endswith(\".tif\")]\n",
    "\n",
    "# Margin pixels\n",
    "margin = 10\n",
    "\n",
    "# Matching images and ROIs for processing\n",
    "for image_path in image_files:\n",
    "    image_file = os.path.basename(image_path)\n",
    "    sample_name = image_file.split(\".\")[0]\n",
    "    image = imread(image_path)\n",
    "    image = np.squeeze(image)\n",
    "    pad_width = ((margin, margin), (margin, margin))\n",
    "\n",
    "    padded_image = np.pad(image, pad_width=pad_width, mode='constant', constant_values=0)\n",
    "\n",
    "    # Otsu's thresholding (uses the G channel if grayscale conversion is required)\n",
    "    if padded_image.ndim == 3:  \n",
    "        padded_gray = padded_image[:, :, 1]\n",
    "    else:\n",
    "        padded_gray = padded_image \n",
    "\n",
    "    threshold_value = threshold_otsu(padded_gray)\n",
    "    binary_image = padded_gray > 40\n",
    "\n",
    "    # Labeling process\n",
    "    labeled_image = label(binary_image)\n",
    "    regions = regionprops(labeled_image)\n",
    "\n",
    "    # Find the largest area\n",
    "    if len(regions) > 0:\n",
    "        largest_region = max(regions, key=lambda r: r.area)\n",
    "        largest_label = largest_region.label\n",
    "\n",
    "        # Keep only the largest regions\n",
    "        largest_component = (labeled_image == largest_label).astype(np.uint8) * 255\n",
    "\n",
    "        # Remove margins and restore to original size\n",
    "        if largest_component.ndim == 3:\n",
    "            final_image = largest_component[margin:-margin, margin:-margin, :]\n",
    "        else:\n",
    "            final_image = largest_component[margin:-margin, margin:-margin]\n",
    "\n",
    "        # save image\n",
    "        save_path = os.path.join(result_savedir, f\"{sample_name}_threshold.tif\")\n",
    "        imsave(save_path, final_image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please make ROI of cell body using \"make_cell_body_ROI.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get params\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tifffile as tiff\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from skimage.measure import perimeter, regionprops, label\n",
    "from skimage.morphology import convex_hull_image\n",
    "from scipy.spatial import ConvexHull, distance\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.morphology import skeletonize\n",
    "from scipy.stats import linregress\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "from skimage.morphology import disk\n",
    "from skimage.graph import route_through_array\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "def box_counting_fractal(binary_img):\n",
    "    \"\"\"\n",
    "    Calculates the fractal dimension of a 2D image using the box-counting method\n",
    "    :param binary_img: 2D binary image (np.ndarray, dtype=bool)\n",
    "    :return: Fractal dimension D\n",
    "    \"\"\"\n",
    "    # List of box sizes (2^0, 2^1, ..., 2^9)\n",
    "    sizes = 2 ** np.arange(10)\n",
    "    counts = []\n",
    "\n",
    "    for size in sizes:\n",
    "        # Calculate the total value for each grid\n",
    "        grid = np.add.reduceat(\n",
    "            np.add.reduceat(binary_img, np.arange(0, binary_img.shape[0], size), axis=0),\n",
    "            np.arange(0, binary_img.shape[1], size), axis=1\n",
    "        )\n",
    "        # Count if the box contains at least one pixel\n",
    "        counts.append(np.count_nonzero(grid))\n",
    "\n",
    "    # Take the logarithm of box size and counts\n",
    "    log_sizes = np.log(sizes)\n",
    "    log_counts = np.log(counts)\n",
    "\n",
    "    # Calculate the fractal dimension by linear regression (absolute value of the gradient)\n",
    "    coeffs = np.polyfit(log_sizes, log_counts, 1)\n",
    "    D = -coeffs[0]\n",
    "\n",
    "    return D\n",
    "\n",
    "\n",
    "def lacunarity(binary_img):\n",
    "    \"\"\"\n",
    "    Calculates the lacunarity of a 2D image using the box-counting method\n",
    "    :param binary_img: 2D binary image (np.ndarray, dtype=bool)\n",
    "    :return: Lacunarity value\n",
    "    \"\"\"\n",
    "    # List of box sizes (2^0, 2^1, ..., 2^9)\n",
    "    sizes = 2 ** np.arange(10)\n",
    "    lacunarity_vals = []\n",
    "\n",
    "    for size in sizes:\n",
    "        grid = np.add.reduceat(\n",
    "            np.add.reduceat(binary_img, np.arange(0, binary_img.shape[0], size), axis=0),\n",
    "            np.arange(0, binary_img.shape[1], size), axis=1\n",
    "        )\n",
    "\n",
    "        # Calculate the mean and variance of pixel counts\n",
    "        mean_val = np.mean(grid)\n",
    "        var_val = np.var(grid)\n",
    "\n",
    "        # Calculate lacunarity (variance/mean^2)\n",
    "        if mean_val > 0:\n",
    "            lacunarity_vals.append(var_val / mean_val**2 + 1)\n",
    "\n",
    "    # Returns the average lacunarity\n",
    "    return np.mean(lacunarity_vals) if lacunarity_vals else np.nan\n",
    "\n",
    "\n",
    "def sholl_analysis(skeleton, centroid, max_radius=50, step_size=5):\n",
    "    \"\"\"A function that performs a Sholl analysis (counts the number of intersections on a circle)\"\"\"\n",
    "    radii = np.arange(step_size, max_radius + step_size, step_size, dtype=np.float64)\n",
    "    intersections = []\n",
    "    skeleton_coords = np.column_stack(np.where(skeleton == 1))\n",
    "    \n",
    "    for r in radii:\n",
    "        mask = np.isclose(np.sqrt(np.sum((skeleton_coords - centroid) ** 2, axis=1)), r, atol=0.5)\n",
    "        intersections.append(np.sum(mask))\n",
    "    \n",
    "    intersections_np = np.array(intersections, dtype=np.float64)\n",
    "    slope, intercept, r_value, _, _ = linregress(radii, intersections_np)\n",
    "    \n",
    "    return radii, intersections, slope, intercept\n",
    "\n",
    "\n",
    "def get_max_process_length(skeleton):\n",
    "    \"\"\" Find the longest path between the endpoints of a skeleton image \"\"\"\n",
    "    skel_coords = np.column_stack(np.where(skeleton > 0))\n",
    "    if len(skel_coords) == 0:\n",
    "        return 0\n",
    "\n",
    "    # Cost map (only pixels on skeleton are passable)\n",
    "    cost_map = np.full(skeleton.shape, np.inf)\n",
    "    cost_map[skeleton > 0] = 1  # Set the cost of pixels on the skeleton to 1\n",
    "\n",
    "    # Get the corner points (points with only one adjacent pixel)\n",
    "    endpoints = [tuple(p) for p in skel_coords if np.sum(skeleton[max(0, p[0]-1):p[0]+2, max(0, p[1]-1):p[1]+2]) == 2]\n",
    "\n",
    "    max_length = 0\n",
    "    longest_path = None\n",
    "\n",
    "    # Examine all endpoint pairs\n",
    "    for i in range(len(endpoints)):\n",
    "        for j in range(i + 1, len(endpoints)):\n",
    "            path, cost = route_through_array(cost_map, endpoints[i], endpoints[j], fully_connected=True)\n",
    "            if cost > max_length:\n",
    "                max_length = cost\n",
    "                longest_path = path\n",
    "\n",
    "    return max_length, longest_path\n",
    "\n",
    "def get_straightness_index(skeleton):\n",
    "    \"\"\" Function to calculate straightness from skeleton image \"\"\"\n",
    "    skel_coords = np.column_stack(np.where(skeleton > 0))  # Get skeleton coordinates\n",
    "    if len(skel_coords) == 0:\n",
    "        return 0  # Returns 0 if the skeleton does not exist.\n",
    "\n",
    "    # Cost map (only pixels on skeleton are passable)\n",
    "    cost_map = np.full(skeleton.shape, np.inf)\n",
    "    cost_map[skeleton > 0] = 1  # \n",
    "\n",
    "    # Get the corner points (points with only one adjacent pixel)\n",
    "    endpoints = [tuple(p) for p in skel_coords if np.sum(skeleton[max(0, p[0]-1):p[0]+2, max(0, p[1]-1):p[1]+2]) == 2]\n",
    "\n",
    "    if len(endpoints) < 2:\n",
    "        return 0\n",
    "\n",
    "    max_straightness = 0\n",
    "\n",
    "    # Examine all endpoint pairs\n",
    "    for i in range(len(endpoints)):\n",
    "        for j in range(i + 1, len(endpoints)):\n",
    "            path, cost = route_through_array(cost_map, endpoints[i], endpoints[j], fully_connected=True)\n",
    "            euclidean_distance = euclidean(endpoints[i], endpoints[j]) \n",
    "            if cost > 0:\n",
    "                straightness = euclidean_distance / cost\n",
    "                max_straightness = max(max_straightness, straightness)\n",
    "\n",
    "    return max_straightness\n",
    "\n",
    "\n",
    "def compute_morphological_features(image_path, pixel_size=0.28, perimeter_pixel=0.3):\n",
    "    \"\"\" Morphological analysis of microglia\"\"\"\n",
    "\n",
    "    # Image loading\n",
    "    binary_img = tiff.imread(image_path)\n",
    "    binary_img = binary_img > threshold_otsu(binary_img)\n",
    "    labeled_img = label(binary_img)\n",
    "\n",
    "    # Keep only the largest regions\n",
    "    regions = regionprops(labeled_img)\n",
    "    if len(regions) == 0:\n",
    "        print(f\"Warning!: No parsable object at {image_path}\")\n",
    "        return {}, None\n",
    "    \n",
    "    region = max(regions, key=lambda r: r.area)\n",
    "    largest_label = region.label\n",
    "    largest_component = (labeled_img == largest_label).astype(np.uint8) * 255\n",
    "\n",
    "    Fractal_d = box_counting_fractal(largest_component)\n",
    "    lacunality_value = lacunarity(largest_component)\n",
    "\n",
    "    ## Calculate the convex hull\n",
    "    convex_hull = convex_hull_image(largest_component)\n",
    "    convex_labels = label(convex_hull.astype(int))\n",
    "    convex_regions = regionprops(convex_labels)\n",
    "\n",
    "    if len(convex_regions) == 0:\n",
    "        print(f\"Warning!: No parsable object at {image_path}\")\n",
    "        return {}, None\n",
    "    \n",
    "    convex_region = convex_regions[0]\n",
    "\n",
    "\n",
    "    cell_area = region.area * pixel_size ** 2  # µm²\n",
    "    convex_area = convex_region.area * pixel_size ** 2\n",
    "    cell_perimeter = perimeter(largest_component > 0) * perimeter_pixel\n",
    "    convex_perimeter = perimeter(convex_hull>0) * perimeter_pixel\n",
    "    density = cell_area / convex_area\n",
    "    roughness = cell_perimeter / convex_perimeter\n",
    "    circularity = (4 * np.pi * cell_area) / (cell_perimeter ** 2)\n",
    "    convex_circularity = (4 * np.pi * convex_area) / (convex_perimeter ** 2)\n",
    "\n",
    "    \"\"\"skeleton analyze\"\"\"\n",
    "    skeleton = skeletonize(binary_img)\n",
    "    labeled_img = label(skeleton)\n",
    "    regions = regionprops(labeled_img)\n",
    "\n",
    "    if len(regions) == 0:\n",
    "        print(f\"Warning!: No parsable object at {image_path}\")\n",
    "        return {}\n",
    "\n",
    "    region = max(regions, key=lambda r: r.area)\n",
    "    largest_label = region.label\n",
    "    largest_component = (labeled_img == largest_label).astype(np.uint8) * 255\n",
    "\n",
    "    # get analysis results\n",
    "    total_process_length = np.sum(skeleton)\n",
    "    num_branch_points = np.sum(perimeter(skeleton))\n",
    "    mean_process_length = total_process_length / max(1, num_branch_points)\n",
    "    centroid = region.centroid\n",
    "\n",
    "    # Sholl analysis\n",
    "    sholl_radii, sholl_intersections, sholl_slope, sholl_intercept = sholl_analysis(skeleton, centroid)\n",
    "    sholl_max_counts = max(sholl_intersections) \n",
    "\n",
    "    # process length\n",
    "    max_process_length = get_max_process_length(skeleton)\n",
    "\n",
    "    # straghtness\n",
    "    straightness = get_straightness_index(skeleton)\n",
    "\n",
    "    # Calculate 2D distance map\n",
    "    distance_map = distance_transform_edt(binary_img)\n",
    "\n",
    "    # Finding the center of the cell body\n",
    "    max_dist_idx = np.argmax(distance_map)\n",
    "    cell_center = np.unravel_index(max_dist_idx, distance_map.shape)\n",
    "\n",
    "    # Obtaining the coordinates of the cell membrane\n",
    "    cell_boundary = labeled_img == region.label\n",
    "    boundary_coords = np.array(np.where(cell_boundary)).T\n",
    "\n",
    "    # Calculate the distance from the center of the cell body to the cell membrane\n",
    "    distances = np.sqrt(np.sum((boundary_coords - np.array(cell_center))**2, axis=1))\n",
    "\n",
    "    properties = {\n",
    "        \"Fractal_dimension\": Fractal_d,\n",
    "        \"lacunality\":lacunality_value,\n",
    "        \"Cell Area (µm²)\": cell_area,\n",
    "        \"Convex Hull Area (µm²)\": convex_area,\n",
    "        \"Density\": density,\n",
    "        \"Cell Perimeter (µm)\": cell_perimeter,\n",
    "        \"Convex Hull Perimeter (µm)\": convex_perimeter,\n",
    "        \"Roughness\": roughness,\n",
    "        \"Convex Hull Circularity\": convex_circularity,\n",
    "        \"Cell Circularity\": circularity,\n",
    "\n",
    "        \"Total_Process_Length\": total_process_length,\n",
    "        \"Mean_Process_Length\": mean_process_length,\n",
    "        \"Max_Process_Length\": max_process_length[0],\n",
    "        \"Sholl_Max_Counts\": sholl_max_counts,\n",
    "        \"Straightness\": straightness,\n",
    "    }\n",
    "    \n",
    "    return properties, largest_component\n",
    "\n",
    "\n",
    "# Analysis directory settings\n",
    "image_dir = \"Threshold\"\n",
    "image_files = [os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.endswith(\".tif\")]\n",
    "\n",
    "results_morpho = []\n",
    "\n",
    "for image_path in tqdm(image_files):\n",
    "    parameters, largest_component = compute_morphological_features(image_path)\n",
    "    sample_name = os.path.basename(image_path)\n",
    "    \n",
    "    if parameters:\n",
    "        parameters[\"sample\"] = sample_name.split(\"_\")[0]\n",
    "        parameters[\"mouse\"] = sample_name.split(\"_\")[0].split(\"-\")[1]\n",
    "\n",
    "        results_morpho.append(parameters)\n",
    "\n",
    "def load_shapes_json(json_path):\n",
    "    \"\"\"Load ROI data from JSON\"\"\"\n",
    "    with open(json_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    return data[\"cell_body_rois\"]\n",
    "\n",
    "def calculate_polygon_area(polygon):\n",
    "    \"\"\"\n",
    "    Takes the coordinates of the vertices of a polygon and calculates its area using Shoelace's formula\n",
    "    polygon: List of [(x1, y1), (x2, y2), ..., (xn, yn)]\n",
    "    \"\"\"\n",
    "    polygon = np.array(polygon)  # Numpy\n",
    "    x = polygon[:, 0]\n",
    "    y = polygon[:, 1]\n",
    "\n",
    "    # Shoelace Official\n",
    "    area = 0.5 * np.abs(np.dot(x, np.roll(y, 1)) - np.dot(y, np.roll(x, 1)))\n",
    "    return area\n",
    "\n",
    "# Analysis directory settings for cell body\n",
    "ROI_dir = \"ROI_json_cell_body\"\n",
    "roi_files = [os.path.join(ROI_dir, f) for f in os.listdir(ROI_dir) if f.endswith(\".json\")]\n",
    "\n",
    "results_cell_body_area = []\n",
    "sample_list = []\n",
    "\n",
    "for roi_path in tqdm(roi_files):\n",
    "    sample_name = os.path.basename(roi_path).split('.')[0].split(\"_\")[0]\n",
    "    cell_body_rois = load_shapes_json(roi_path)\n",
    "\n",
    "    # Sum the area of ​​all ROIs\n",
    "    total_area = sum(calculate_polygon_area(roi) for roi in cell_body_rois)\n",
    "\n",
    "    # Convert pixels to μm²\n",
    "    pixel_size = 0.28  # please enter your pixel size\n",
    "    area_um2 = total_area * (pixel_size ** 2)\n",
    "\n",
    "    results_cell_body_area.append(area_um2)\n",
    "    sample_list.append(sample_name) \n",
    "\n",
    "# Creating a data frame\n",
    "df_cell_body = pd.DataFrame({\"sample\": sample_list, \"Cell body Area (μm²)\": results_cell_body_area})\n",
    "\n",
    "# save\n",
    "if results_morpho:\n",
    "    df = pd.DataFrame(results_morpho)\n",
    "    df = pd.merge(df, df_cell_body, on=\"sample\")\n",
    "    csv_path =\"morphology_results_Iba1.csv\"\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(f\"The morphology analysis results have been saved in {csv_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "morphology_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
