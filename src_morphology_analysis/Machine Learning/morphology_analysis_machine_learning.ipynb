{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import skew, kurtosis\n",
    "import scipy.cluster.hierarchy as sch\n",
    "from scipy.spatial.distance import pdist\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "\n",
    "csv_iba1_path = r\"use\\morphology_results.csv\" # morphology file\n",
    "csv_contra_path = r\"use\\morphology_results_control.csv\" # morphology file control\n",
    "\n",
    "df_iba1 = pd.read_csv(csv_iba1_path)\n",
    "df_contra = pd.read_csv(csv_contra_path)\n",
    "df_iba1.insert(2, 'lateral', 'ipsi')\n",
    "df_contra.insert(2, 'lateral', 'contra')\n",
    "df = pd.concat([df_iba1, df_contra], ignore_index=True)\n",
    "df_value = df.drop(columns=['lateral', 'mouse', 'sample']).copy()\n",
    "n_samples, n_features = df_value.shape\n",
    "df_value.replace([np.inf, -np.inf], np.nan, inplace=True)  # Convert inf to NaN\n",
    "df_value.fillna(df_value.mean(), inplace=True)  # Fill NaN with the average value of each column\n",
    "df_value\n",
    "\n",
    "# standardization\n",
    "scaler = MinMaxScaler()\n",
    "df_scaled = pd.DataFrame(scaler.fit_transform(df_value), columns=df_value.columns)\n",
    "\n",
    "def calculate_mmi(data):\n",
    "    \"\"\"多峰性指数（MMI）を計算\"\"\"\n",
    "    n = len(data)\n",
    "    M3 = skew(data)  # skewness\n",
    "    M4 = kurtosis(data)  # Kurtosis (using Fisher's definition)\n",
    "    \n",
    "    if n < 4:\n",
    "        return np.nan\n",
    "\n",
    "    MMI = (M3**2 + 1) / (M4 + 3 * ((n - 1)**2 / ((n - 2) * (n - 3))))\n",
    "    return MMI\n",
    "\n",
    "# Calculate the MMI for each feature\n",
    "mmi_values = df_scaled.apply(calculate_mmi)\n",
    "print(mmi_values, end=\"\\n\\n\")\n",
    "\n",
    "# Select features according to the MMI value (e.g., MMI ≥ 0.5)\n",
    "selected_features = mmi_values[mmi_values >= 0.5].index.tolist()\n",
    "print(\"selected features\")\n",
    "for fe in selected_features:\n",
    "    print(fe)\n",
    "\n",
    "# Use only selected features\n",
    "df_selected = df_scaled[selected_features]\n",
    "df_selected = df_selected.apply(pd.to_numeric, errors='coerce')\n",
    "df_selected = df_selected.dropna()\n",
    "print(df_selected.head())\n",
    "\n",
    "\n",
    "# Testing for an appropriate number of clusters\n",
    "X = df_selected\n",
    "kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
    "labels = kmeans.fit_predict(X)\n",
    "scores = []\n",
    "k_range = range(2, 10)  # Evaluated with cluster counts of 2 to 9\n",
    "\n",
    "# silhouette score\n",
    "best_k = 0\n",
    "scores = []\n",
    "best_score = -1\n",
    "\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    labels = kmeans.fit_predict(X)\n",
    "    score = silhouette_score(X, labels)\n",
    "    if score > best_score:\n",
    "        print(score)\n",
    "        best_score = score\n",
    "        best_k = k\n",
    "    scores.append(score)\n",
    "\n",
    "# plot\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(k_range, scores, marker='o')\n",
    "plt.xlabel(\"Number of Clusters\", fontsize=18)\n",
    "plt.ylabel(\"Silhouette Score\", fontsize=18)\n",
    "plt.tick_params(axis='x', labelsize=16)\n",
    "plt.tick_params(axis='y', labelsize=16)\n",
    "plt.title(\"Optimal Cluster Selection using Silhouette Score\")\n",
    "plt.gca().spines[\"right\"].set_visible(False)\n",
    "plt.gca().spines[\"top\"].set_visible(False)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Weighting using MMI (contribution ratio) (temporary value, replace with actual MMI)\n",
    "mmi_weights = {}\n",
    "for i in range(len(df_value.columns)):\n",
    "    mmi_weights[df_value.columns[i]] = mmi_values[i]\n",
    "\n",
    "# Normalize features (Min-Max scaling)\n",
    "scaler = MinMaxScaler()\n",
    "df_scaled = pd.DataFrame(scaler.fit_transform(df_value[mmi_weights.keys()]), columns=mmi_weights.keys())\n",
    "\n",
    "# Classification of features\n",
    "ameboid_features = [\n",
    "    'Cell Area (µm²)',\n",
    "    'Density', \n",
    "    'Convex Hull Circularity', \n",
    "    'Cell Circularity',\n",
    "    'Cell body Area (μm²)'\n",
    "    ]\n",
    "\n",
    "ramified_features = [\n",
    "    'Fractal_dimention', \n",
    "    'lacnaulity', \n",
    "    'Convex Hull Area (µm²)', \n",
    "    'Cell Perimeter (µm)', \n",
    "    'Convex Hull Perimeter (µm)', \n",
    "    'Roughness',   \n",
    "    'Total_Process_Length', \n",
    "    'Mean_Process_Length', \n",
    "    'Max_Process_Length',\n",
    "    'Sholl_Max_Counts', \n",
    "    'Straightness'\n",
    "    ]\n",
    "\n",
    "# Score calculation\n",
    "df_scaled[\"Amoeboid_Score\"] = df_scaled[ameboid_features].mul([mmi_weights[f] for f in ameboid_features], axis=1).sum(axis=1)\n",
    "df_scaled[\"Ramified_Score\"] = df_scaled[ramified_features].mul([mmi_weights[f] for f in ramified_features], axis=1).sum(axis=1)\n",
    "\n",
    "# Maximum score calculation\n",
    "max_value_ameboid = np.dot(np.ones(len(ameboid_features)), [mmi_weights[f] for f in ameboid_features])\n",
    "max_value_ramified = np.dot(np.ones(len(ramified_features)), [mmi_weights[f] for f in ramified_features])\n",
    "\n",
    "# Calculate minimum score\n",
    "min_value_ameboid = 0\n",
    "min_value_ramified = 0\n",
    "\n",
    "# resule\n",
    "print(f\"Max score: ram={max_value_ramified} , ame={max_value_ameboid}\")\n",
    "print(f\"Min score: ram={min_value_ramified} , ame={min_value_ameboid}\")\n",
    "\n",
    "min_value = min_value_ameboid - max_value_ramified\n",
    "max_value = max_value_ameboid - min_value_ramified\n",
    "\n",
    "print(f\"type score max: { max_value_ameboid - min_value_ramified}\")\n",
    "print(f\"type score min: { min_value_ameboid - max_value_ramified}\")\n",
    "\n",
    "scaler_type_ameboid = MinMaxScaler(feature_range=(min_value_ameboid, max_value_ameboid))\n",
    "df_scaled[\"Amoeboid_Score_scaled\"] = scaler_type_ameboid.fit_transform(df_scaled[\"Amoeboid_Score\"].values.reshape(-1, 1))\n",
    "\n",
    "scaler_type_ramified = MinMaxScaler(feature_range=(min_value_ramified, max_value_ramified))\n",
    "df_scaled[\"Ramified_Score_scaled\"] = scaler_type_ameboid.fit_transform(df_scaled[\"Ramified_Score\"].values.reshape(-1, 1))\n",
    "\n",
    "#  Scale min-max to 0-100\n",
    "def scale_score(value, min_value, max_value):\n",
    "    return ((value - min_value) / (max_value - min_value)) * 100 if max_value != min_value else 0\n",
    "\n",
    "# Classification (classify into higher score)\n",
    "df_scaled[\"Morphology_Type\"] = np.where(\n",
    "    df_scaled[\"Amoeboid_Score_scaled\"] > df_scaled[\"Ramified_Score_scaled\"], \"Amoeboid\", \"Ramified\"\n",
    ")\n",
    "\n",
    "Microglia_Type_list = df_scaled[\"Morphology_Type\"].copy()\n",
    "\n",
    "# check results\n",
    "print(df_scaled[[\"Amoeboid_Score\", \"Ramified_Score\", \"Morphology_Type\"]].head())\n",
    "\n",
    "df_scaled_save_vesion = df_scaled.copy()\n",
    "df_scaled_save_vesion[\"sample\"] = df[\"sample\"]\n",
    "\n",
    "# save\n",
    "df_scaled_save_vesion.to_csv(\"classified_morphology.csv\", index=False)\n",
    "\n",
    "df_scaled[\"Type_Score_Sum\"] = df_scaled[\"Amoeboid_Score\"]  - df_scaled[\"Ramified_Score\"]\n",
    "df_scaled[\"Type_Score_Scaled\"] = scale_score(df_scaled[\"Type_Score_Sum\"], min_value, max_value)\n",
    "\n",
    "df_scaled['Group'] = df[\"mouse\"] + \"-\" + df[\"lateral\"]\n",
    "df_scaled[\"mouse\"] = df[\"mouse\"]\n",
    "\n",
    "# Performing hierarchical clustering-----------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "distance_matrix = pdist(df_selected, metric='euclidean') # Calculating the Euclidean Distance Matrix\n",
    "\n",
    "# [Applying clustering] \n",
    "cluster_number = 4\n",
    "distance_matrix = pdist(df_selected, metric='euclidean')\n",
    "linkage_matrix = sch.linkage(distance_matrix, method='ward')\n",
    "optimal_clusters = sch.fcluster(linkage_matrix, cluster_number, criterion='maxclust')\n",
    "\n",
    "df_selected[\"Cluster\"] = optimal_clusters\n",
    "\n",
    "# Add experimental group information\n",
    "df_selected[\"Group\"] = df[\"mouse\"] + \"-\" + df[\"lateral\"]  \n",
    "df_clustering_save = df_selected.copy()\n",
    "df_clustering_save[\"sample\"] = df[\"sample\"]\n",
    "\n",
    "clustering_save_dir = r\"morphology_analysis\\Machine Learning\" # save dir\n",
    "clustering_save_path = os.path.join(clustering_save_dir, \"selected_clustering.csv\")\n",
    "df_clustering_save.to_csv(clustering_save_path)\n",
    "\n",
    "# Statistics by cluster (numeric data only)\n",
    "summary = df_selected.groupby([\"Group\", \"Cluster\"]).mean()\n",
    "print(\"\\nCluster Statistics by Group:\")\n",
    "print(summary)\n",
    "\n",
    "# [Application of PCA] Dimensionality reduction to 2 dimensions\n",
    "pca = PCA(n_components=2)\n",
    "df_pca = pca.fit_transform(df_selected.drop(columns=[\"Cluster\", \"Group\"])) \n",
    "\n",
    "# Obtain the coefficients of the principal components\n",
    "loadings = pd.DataFrame(pca.components_.T, columns=[f\"PC{i+1}\" for i in range(pca.n_components_)], index=df_selected.drop(columns=[\"Cluster\", \"Group\"]).columns)\n",
    "print(f\"Loadings: {loadings}\")\n",
    "\n",
    "# Calculate the cumulative variance\n",
    "explained_variance_ratio = pca.explained_variance_ratio_ * 100  # Convert 0-1 to percentage (%)\n",
    "cumulative_variance = np.cumsum(explained_variance_ratio)\n",
    "\n",
    "print(\"Cumulative variance\")\n",
    "for i, (var, cum_var) in enumerate(zip(explained_variance_ratio, cumulative_variance)):\n",
    "    print(f\"PC{i+1}: {var:.2f}% (cumulative {cum_var:.2f}%)\")\n",
    "\n",
    "# Save the results of PCA in a data frame\n",
    "df_pca = pd.DataFrame(df_pca, columns=[\"PC1\", \"PC2\"])\n",
    "df_pca[\"Cluster\"] = df_selected[\"Cluster\"]\n",
    "df_pca[\"Group\"] = df_selected[\"Group\"]\n",
    "df_pca[\"Morphology_Type\"] = Microglia_Type_list\n",
    "df_pca[\"lateral\"] = df[\"lateral\"]\n",
    "df_pca[\"lateral-type\"] = df[\"lateral\"] + \"-\" + Microglia_Type_list\n",
    "df_pca[\"mouse\"] = df[\"mouse\"]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "morphology_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
